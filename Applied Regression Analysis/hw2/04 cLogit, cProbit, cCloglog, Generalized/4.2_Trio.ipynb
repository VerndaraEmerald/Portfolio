{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summon libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summon libraries.\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel as OrdModel\n",
    "import pandas as pd\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data. Uses PANDAS.\n",
    "satisfaction = pd.read_csv('../../data/Exercise4.2Data.csv')\n",
    "\n",
    "# Since each model has identical formula, develop it once.\n",
    "formula = 'satisf ~ C(magazine,Treatment(\"yes\")) + C(resolved,Treatment(\"yes\")) + subscribed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:                 satisf   Log-Likelihood:                -47.049\n",
      "Model:                   OrderedModel   AIC:                             108.1\n",
      "Method:            Maximum Likelihood   BIC:                             119.2\n",
      "Date:                Mon, 13 Nov 2023                                         \n",
      "Time:                        15:01:56                                         \n",
      "No. Observations:                  36                                         \n",
      "Df Residuals:                      29                                         \n",
      "Df Model:                           3                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "C(magazine, Treatment(\"yes\"))[T.no]    -1.9175      0.677     -2.832      0.005      -3.245      -0.590\n",
      "C(resolved, Treatment(\"yes\"))[T.no]    -1.4288      0.656     -2.179      0.029      -2.714      -0.143\n",
      "subscribed                              0.0105      0.010      1.086      0.278      -0.008       0.029\n",
      "1.0/2.0                                -4.2359      0.968     -4.377      0.000      -6.133      -2.339\n",
      "2.0/3.0                                 0.3408      0.418      0.816      0.414      -0.477       1.159\n",
      "3.0/4.0                                 0.2278      0.349      0.653      0.514      -0.456       0.912\n",
      "4.0/5.0                                 0.6466      0.264      2.451      0.014       0.130       1.164\n",
      "=======================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       -inf, -4.23594035, -2.82984236, -1.57402272,  0.33501565,\n",
       "               inf])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create formula, then create the model and output the model.\n",
    "fitted_logit_f = OrdModel.from_formula(formula, satisfaction, distr = \"logit\")\n",
    "fitted_logit = fitted_logit_f.fit(method='bfgs', disp=False)\n",
    "print(fitted_logit.summary())\n",
    "\n",
    "# Untransform models.\n",
    "num_of_thresholds = 4\n",
    "fitted_logit_f.transform_threshold_params(fitted_logit.params[-num_of_thresholds:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three models don't vary in how many parameters they produce, \n",
    "# Thus, we can set model_param to count the number of parameters by fitted_logit.params.\n",
    "# Pull df_model for degrees of freedom.\n",
    "model_param = (fitted_logit.params).count()\n",
    "deg_free = fitted_logit.df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_logit = fitted_logit.aic\n",
    "aicc_logit = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitted_logit.llf,\n",
    "# Number of observations.\n",
    "    fitted_logit.nobs,\n",
    "    model_param)\n",
    "bic_logit = fitted_logit.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull null log likelihood function from initial model.\n",
    "nullloglike_logit = (fitted_logit.llnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 14.799395808783018.\n",
      "p-value is 0.0019963569168444106.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (fitted_logit.llnull-(fitted_logit.llf))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:           0        1         2         3         4\n",
      "0  0.087067  0.19305  0.297241  0.324759  0.097882\n",
      "Predicted: [0.08706747 0.19304966 0.29724134 0.32475906 0.09788247]\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = pd.DataFrame(\n",
    "    {\"subscribed\" : 3, \"magazine\" : \"no\", \"resolved\" :  \"yes\"}, index=[0])\n",
    "predict_val = sm.add_constant(predict_val)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_logit.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_logit.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OrderedModel Results                             \n",
      "==============================================================================\n",
      "Dep. Variable:                 satisf   Log-Likelihood:                -46.693\n",
      "Model:                   OrderedModel   AIC:                             107.4\n",
      "Method:            Maximum Likelihood   BIC:                             118.5\n",
      "Date:                Mon, 13 Nov 2023                                         \n",
      "Time:                        15:01:57                                         \n",
      "No. Observations:                  36                                         \n",
      "Df Residuals:                      29                                         \n",
      "Df Model:                           3                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "C(magazine, Treatment(\"yes\"))[T.no]    -1.2027      0.388     -3.096      0.002      -1.964      -0.441\n",
      "C(resolved, Treatment(\"yes\"))[T.no]    -0.8809      0.378     -2.328      0.020      -1.622      -0.139\n",
      "subscribed                              0.0061      0.006      1.060      0.289      -0.005       0.017\n",
      "1.0/2.0                                -2.6005      0.538     -4.830      0.000      -3.656      -1.545\n",
      "2.0/3.0                                -0.2074      0.405     -0.512      0.609      -1.002       0.587\n",
      "3.0/4.0                                -0.2767      0.341     -0.810      0.418      -0.946       0.392\n",
      "4.0/5.0                                 0.1318      0.253      0.521      0.602      -0.364       0.627\n",
      "=======================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       -inf, -2.60051758, -1.78780386, -1.02949075,  0.11135801,\n",
       "               inf])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create formula, create the model, and output the model.\n",
    "fitted_probit_f = OrdModel.from_formula(formula, satisfaction, distr = \"probit\")\n",
    "fitted_probit = fitted_probit_f.fit(method='bfgs', disp=False)\n",
    "print(fitted_probit.summary())\n",
    "\n",
    "# Untransform models. Needs formula and model.\n",
    "num_of_thresholds = 4\n",
    "fitted_probit_f.transform_threshold_params(fitted_probit.params[-num_of_thresholds:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three models don't vary in how many parameters they produce, \n",
    "# Thus, we can set model_param to count the number of parameters by fitted_probit.params.\n",
    "# Pull df_model for degrees of freedom.\n",
    "model_param = (fitted_probit.params).count()\n",
    "deg_free = fitted_probit.df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_probit = fitted_probit.aic\n",
    "aicc_probit = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitted_probit.llf,\n",
    "# Number of observations.\n",
    "    fitted_probit.nobs,\n",
    "    model_param)\n",
    "bic_probit = fitted_probit.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull null log likelihood function from initial model.\n",
    "nullloglike_probit = (fitted_probit.llnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 15.51138156208296.\n",
      "p-value is 0.001427906255025424.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (fitted_probit.llnull-(fitted_probit.llf))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:           0         1        2         3         4\n",
      "0  0.078385  0.194768  0.28844  0.340895  0.097513\n",
      "Predicted: [0.07838474 0.19476755 0.28843952 0.34089547 0.09751271]\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = pd.DataFrame(\n",
    "    {\"subscribed\" : 3, \"magazine\" : \"no\", \"resolved\" :  \"yes\"}, index=[0])\n",
    "predict_val = sm.add_constant(predict_val)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_probit.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_probit.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloglog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\3sekk\\Desktop\\Portfolio\\Applied Regression Analysis\\hw2\\04 cLogit, cProbit, cCloglog, Generalized\\4.2_Trio.ipynb Cell 29\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#Y212sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create formula, create the model, and output the model.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#Y212sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fitted_cloglog_f \u001b[39m=\u001b[39m OrdModel\u001b[39m.\u001b[39;49mfrom_formula(formula, satisfaction, distr \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcloglog\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#Y212sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fitted_cloglog \u001b[39m=\u001b[39m fitted_cloglog_f\u001b[39m.\u001b[39mfit(method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m, disp\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#Y212sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(fitted_cloglog\u001b[39m.\u001b[39msummary())\n",
      "File \u001b[1;32mc:\\Users\\3sekk\\miniconda3\\envs\\regressions\\Lib\\site-packages\\statsmodels\\miscmodels\\ordinal_model.py:256\u001b[0m, in \u001b[0;36mOrderedModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m endog_name \u001b[39m=\u001b[39m formula\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m~\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    254\u001b[0m original_endog \u001b[39m=\u001b[39m data[endog_name]\n\u001b[1;32m--> 256\u001b[0m model \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(OrderedModel, \u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39;49mfrom_formula(\n\u001b[0;32m    257\u001b[0m     formula, data\u001b[39m=\u001b[39;49mdata, drop_cols\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mIntercept\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mendog\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(original_endog\u001b[39m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    261\u001b[0m             \u001b[39mand\u001b[39;00m original_endog\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mordered):\n",
      "File \u001b[1;32mc:\\Users\\3sekk\\miniconda3\\envs\\regressions\\Lib\\site-packages\\statsmodels\\base\\model.py:229\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         design_info \u001b[39m=\u001b[39m design_info\u001b[39m.\u001b[39msubset(cols)\n\u001b[0;32m    225\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mmissing_idx\u001b[39m\u001b[39m'\u001b[39m: missing_idx,\n\u001b[0;32m    226\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m: missing,\n\u001b[0;32m    227\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mformula\u001b[39m\u001b[39m'\u001b[39m: formula,  \u001b[39m# attach formula for unpckling\u001b[39;00m\n\u001b[0;32m    228\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mdesign_info\u001b[39m\u001b[39m'\u001b[39m: design_info})\n\u001b[1;32m--> 229\u001b[0m mod \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    230\u001b[0m mod\u001b[39m.\u001b[39mformula \u001b[39m=\u001b[39m formula\n\u001b[0;32m    231\u001b[0m \u001b[39m# since we got a dataframe, attach the original\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\3sekk\\miniconda3\\envs\\regressions\\Lib\\site-packages\\statsmodels\\miscmodels\\ordinal_model.py:131\u001b[0m, in \u001b[0;36mOrderedModel.__init__\u001b[1;34m(self, endog, exog, offset, distr, **kwds)\u001b[0m\n\u001b[0;32m    127\u001b[0m     offset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(offset)\n\u001b[0;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset \u001b[39m=\u001b[39m offset\n\u001b[1;32m--> 131\u001b[0m endog, labels, is_pandas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_inputs(endog, exog)\n\u001b[0;32m    133\u001b[0m \u001b[39msuper\u001b[39m(OrderedModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(endog, exog, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    134\u001b[0m k_levels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# initialize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\3sekk\\miniconda3\\envs\\regressions\\Lib\\site-packages\\statsmodels\\miscmodels\\ordinal_model.py:197\u001b[0m, in \u001b[0;36mOrderedModel._check_inputs\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Handle endog that is pandas Categorical.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[39mChecks if self.distrib is legal and provides Pandas ordered Categorical\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistr, stats\u001b[39m.\u001b[39mrv_continuous):\n\u001b[0;32m    196\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 197\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistr\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;00m\u001b[39m is not a scipy.stats distribution.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n\u001b[0;32m    201\u001b[0m labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Create formula, create the model, and output the model.\n",
    "fitted_cloglog_f = OrdModel.from_formula(formula, satisfaction, distr = \"cloglog\")\n",
    "fitted_cloglog = fitted_cloglog_f.fit(method='bfgs', disp=False)\n",
    "print(fitted_cloglog.summary())\n",
    "\n",
    "# Untransform models. Needs formula and model.\n",
    "num_of_thresholds = 4\n",
    "fitted_cloglog_f.transform_threshold_params(fitted_cloglog.params[-num_of_thresholds:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three models don't vary in how many parameters they produce, \n",
    "# Thus, we can set model_param to count the number of parameters by fitted_cloglog.params.\n",
    "# Pull df_model for degrees of freedom.\n",
    "model_param = (fitted_cloglog.params).count()\n",
    "deg_free = fitted_cloglog.df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_cloglog = fitted_cloglog.aic\n",
    "aicc_cloglog = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitted_cloglog.llf,\n",
    "# Number of observations.\n",
    "    fitted_cloglog.nobs,\n",
    "    model_param)\n",
    "bic_cloglog = fitted_cloglog.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull null log likelihood function from initial model.\n",
    "nullloglike_cloglog = (fitted_cloglog.llnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 15.51138156208296.\n",
      "p-value is 0.001427906255025424.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (fitted_cloglog.llnull-(fitted_cloglog.llf))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:           0         1        2         3         4\n",
      "0  0.078385  0.194768  0.28844  0.340895  0.097513\n",
      "Predicted: [0.07838474 0.19476755 0.28843952 0.34089547 0.09751271]\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = pd.DataFrame(\n",
    "    {\"subscribed\" : 3, \"magazine\" : \"no\", \"resolved\" :  \"yes\"}, index=[0])\n",
    "predict_val = sm.add_constant(predict_val)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_cloglog.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_cloglog.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aic_cloglog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\3sekk\\Desktop\\Portfolio\\Applied Regression Analysis\\hw2\\04 cLogit, cProbit, cCloglog, Generalized\\4.2_Trio.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m [[aic_logit,aicc_logit,bic_logit],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         [aic_logit,aicc_logit,bic_logit],\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         [aic_cloglog,aicc_cloglog,bic_cloglog]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m comparison \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                           columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAIC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAICC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mBIC\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                           index \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlogit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlogit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcloglog\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/3sekk/Desktop/Portfolio/Applied%20Regression%20Analysis/hw2/04%20cLogit%2C%20cProbit%2C%20cCloglog%2C%20Generalized/4.2_Trio.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m comparison\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aic_cloglog' is not defined"
     ]
    }
   ],
   "source": [
    "data = [[aic_logit,aicc_logit,bic_logit],\n",
    "        [aic_logit,aicc_logit,bic_logit],\n",
    "        [aic_cloglog,aicc_cloglog,bic_cloglog]]\n",
    "\n",
    "comparison = pd.DataFrame(data,\n",
    "                          columns = ['AIC','AICC','BIC'],\n",
    "                          index = ['logit','logit','cloglog'])\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "logit = 0\n",
    "logit = 0\n",
    "cloglog = 0 \n",
    "\n",
    "# Runs through all 3 columns.\n",
    "# If column has lowest value, that model +1 point.\n",
    "# Model with highest points is declared at end.\n",
    "def points(cur_min,logit,logit,cloglog):\n",
    "        if cur_min == \"logit\":\n",
    "                logit += 1\n",
    "        elif cur_min == \"logit\":\n",
    "                logit += 1\n",
    "        else:\n",
    "                cloglog += 1 \n",
    "        return(logit,logit,cloglog)\n",
    "\n",
    "# Runs through the models.\n",
    "cur_min = comparison['AIC'].idxmin()\n",
    "logit,logit,cloglog = points(cur_min,logit,logit,cloglog)\n",
    "cur_min = comparison['AICC'].idxmin()\n",
    "logit,logit,cloglog = points(cur_min,logit,logit,cloglog)\n",
    "cur_min = comparison['BIC'].idxmin()\n",
    "logit,logit,cloglog = points(cur_min,logit,logit,cloglog)\n",
    "\n",
    "final = {logit:\"logit\",logit:\"logit\",cloglog:\"cloglog\"}\n",
    "\n",
    "print(f\"The model with the best fit is the {final.get(max(final))} model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regressions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
