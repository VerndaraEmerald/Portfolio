{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawn from https://www.statsmodels.org/dev/examples/notebooks/generated/glm_formula.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summon libraries.\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data. Uses PANDAS.\n",
    "novel = pd.read_csv('../../data/Exercise3.3Data.csv')\n",
    "# Turns success into 0/1.\n",
    "novel['success'] = novel['success'].map({'yes' : 1, 'no' : 0})\n",
    "\n",
    "# Since each model has identical formula, develop it once.\n",
    "formula = 'success ~ cover + C(methods,Treatment(\"none\")) + C(novels,Treatment(\"many\")) + years'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.364448\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                success   No. Observations:                   44\n",
      "Model:                          Logit   Df Residuals:                       37\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 26 Oct 2023   Pseudo R-squ.:                  0.4670\n",
      "Time:                        11:08:16   Log-Likelihood:                -16.036\n",
      "converged:                       True   LL-Null:                       -30.088\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.979e-05\n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -6.8762      2.366     -2.907      0.004     -11.513      -2.240\n",
      "cover[T.yes]                                3.5238      1.312      2.686      0.007       0.952       6.095\n",
      "C(methods, Treatment(\"none\"))[T.many]       3.9286      1.792      2.193      0.028       0.417       7.440\n",
      "C(methods, Treatment(\"none\"))[T.one]        0.7008      1.191      0.588      0.556      -1.634       3.036\n",
      "C(novels, Treatment(\"many\"))[T.first]       1.8768      1.578      1.189      0.234      -1.217       4.970\n",
      "C(novels, Treatment(\"many\"))[T.several]     1.3992      1.325      1.056      0.291      -1.199       3.997\n",
      "years                                       0.2907      0.127      2.291      0.022       0.042       0.539\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "fitted_logit = smf.logit(formula = formula, data=novel).fit()\n",
    "print(fitted_logit.summary())\n",
    "fitloglike_logit = (fitted_logit.llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three models don't vary in how many parameters they produce, \n",
    "# Thus, we can set model_param to fitted.df_model once.\n",
    "# df_model is number of regressors. Add 1 to get number of parameters.\n",
    "# Keep df_model for degrees of freedom.\n",
    "model_param = fitted_logit.df_model + 1\n",
    "deg_free = fitted_logit.df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_logit = fitted_logit.aic\n",
    "aicc_logit = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitloglike_logit,\n",
    "# Number of observations.\n",
    "    fitted_logit.nobs,\n",
    "    model_param)\n",
    "bic_logit = fitted_logit.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683821\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# Null model.\n",
    "null = smf.logit('success ~ 1', data=novel).fit()\n",
    "nullloglike_logit = (null.llf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit log likelihood. Found the names through dir() https://stackoverflow.com/questions/2675028/list-attributes-of-an-object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 28.104794170180533.\n",
      "p-value is 8.978739912679501e-05.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (nullloglike_logit-(fitloglike_logit))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0    0.186086\n",
      "dtype: float64\n",
      "Predicted: 0.18608601384386772\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = pd.DataFrame(\n",
    "    {\"cover\" : \"yes\", \"methods\" : \"none\", \"novels\" : \"first\" , \"years\" : 0}, index=[0])\n",
    "predict_val = sm.add_constant(predict_val)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_logit.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_logit.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.369389\n",
      "         Iterations 7\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                success   No. Observations:                   44\n",
      "Model:                         Probit   Df Residuals:                       37\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 26 Oct 2023   Pseudo R-squ.:                  0.4598\n",
      "Time:                        11:08:16   Log-Likelihood:                -16.253\n",
      "converged:                       True   LL-Null:                       -30.088\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001084\n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -3.6827      1.164     -3.163      0.002      -5.965      -1.401\n",
      "cover[T.yes]                                1.8841      0.645      2.922      0.003       0.621       3.148\n",
      "C(methods, Treatment(\"none\"))[T.many]       2.0626      0.929      2.219      0.026       0.241       3.884\n",
      "C(methods, Treatment(\"none\"))[T.one]        0.2483      0.629      0.395      0.693      -0.985       1.482\n",
      "C(novels, Treatment(\"many\"))[T.first]       0.9553      0.885      1.079      0.280      -0.780       2.690\n",
      "C(novels, Treatment(\"many\"))[T.several]     0.7903      0.742      1.066      0.287      -0.663       2.244\n",
      "years                                       0.1623      0.068      2.389      0.017       0.029       0.295\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "formula = 'success ~ cover + C(methods,Treatment(\"none\")) + C(novels,Treatment(\"many\")) + years'\n",
    "fitted_probit = smf.probit(formula=formula, data=novel).fit()\n",
    "print(fitted_probit.summary())\n",
    "fitloglike_probit = (fitted_probit.llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683821\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "# Null model.\n",
    "null_probit = smf.probit('success ~ 1', data=novel).fit()\n",
    "nullloglike_probit = (null_probit.llf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 27.670024452307146.\n",
      "p-value is 0.0001084039868023412.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (nullloglike_probit-(fitloglike_probit))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_probit = fitted_probit.aic\n",
    "aicc_probit = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitloglike_probit,\n",
    "# Number of observations.\n",
    "    fitted_probit.nobs,\n",
    "    model_param)\n",
    "bic_probit = fitted_probit.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probit prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0    0.199526\n",
      "dtype: float64\n",
      "Predicted: 0.19952619997183002\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = pd.DataFrame(\n",
    "    {\"cover\" : \"yes\", \"methods\" : \"none\", \"novels\" : \"first\" , \"years\" : 0}, index=[0])\n",
    "predict_val = sm.add_constant(predict_val)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_probit.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_probit.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog models. Found format through https://github.com/statsmodels/statsmodels/issues/827. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                success   No. Observations:                   44\n",
      "Model:                            GLM   Df Residuals:                       37\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                CLogLog   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -15.399\n",
      "Date:                Thu, 26 Oct 2023   Deviance:                       30.797\n",
      "Time:                        11:08:16   Pearson chi2:                     47.6\n",
      "No. Iterations:                    13   Pseudo R-squ. (CS):             0.4871\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================================\n",
      "                                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  -6.1473      1.988     -3.093      0.002     -10.043      -2.251\n",
      "cover[T.yes]                                2.8126      0.961      2.926      0.003       0.929       4.696\n",
      "C(methods, Treatment(\"none\"))[T.many]       3.4195      1.377      2.482      0.013       0.720       6.119\n",
      "C(methods, Treatment(\"none\"))[T.one]        0.8348      0.862      0.969      0.333      -0.854       2.523\n",
      "C(novels, Treatment(\"many\"))[T.first]       1.8391      1.303      1.411      0.158      -0.716       4.394\n",
      "C(novels, Treatment(\"many\"))[T.several]     1.2622      1.025      1.232      0.218      -0.746       3.271\n",
      "years                                       0.2187      0.094      2.318      0.020       0.034       0.404\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cloglog. \n",
    "# Note that this uses a binomial family with cloglog link, akin to R.\n",
    "# Furthermore, this similar format can be used for Probit and Logit, just changing the link function.\n",
    "# It just happens there's no smf.cloglog.\n",
    "formula = 'success ~ cover + C(methods,Treatment(\"none\")) + C(novels,Treatment(\"many\")) + years'\n",
    "fitted_cloglog = smf.glm(formula=formula, data=novel,family=sm.families.Binomial(sm.families.links.CLogLog ())).fit()\n",
    "print(fitted_cloglog.summary())\n",
    "fitloglike_cloglog = (fitted_cloglog.llf)\n",
    "\n",
    "# Null model.\n",
    "null_cloglog = smf.glm(formula = 'success ~ 1', data=novel, family=sm.families.Binomial(sm.families.links.CLogLog ())).fit()\n",
    "nullloglike_cloglog = (null_cloglog.llf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance statistic is 29.379122948607332.\n",
      "p-value is 5.156521244931156e-05.\n"
     ]
    }
   ],
   "source": [
    "# Uses null and fitted log likelihoods to perform the deviance test.\n",
    "deviance= -2 * (nullloglike_cloglog-(fitloglike_cloglog))\n",
    "print(f\"Deviance statistic is {deviance}.\")\n",
    "# Chi2.cdf is from scipy.stats.\n",
    "from scipy.stats import chi2\n",
    "pvalue = 1 - chi2.cdf(deviance,deg_free)\n",
    "print(f\"p-value is {pvalue}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog AIC, BIC, AICC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC, BIC are built into the regression. \n",
    "# AICC needs to be developed.\n",
    "aic_cloglog = fitted_cloglog.aic\n",
    "aicc_cloglog = sm.tools.eval_measures.aicc(\n",
    "# Value of log likelihood function.\n",
    "    fitloglike_cloglog,\n",
    "# Number of observations.\n",
    "    fitted_cloglog.nobs,\n",
    "    model_param)\n",
    "# statsmodel alludes to using a deviance-based bic.\n",
    "# _llf makes it use a log-likelihood function-based bic.\n",
    "bic_cloglog = fitted_cloglog.bic_llf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloglog prediction. https://www.statology.org/statsmodels-predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({\"cover\" : \"yes\", \"methods\" : \"none\", \"novels\" : \"first\" , \"years\" : 0},index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0    0.200779\n",
      "dtype: float64\n",
      "Predicted: 0.20077857938007804\n"
     ]
    }
   ],
   "source": [
    "# Prediction.\n",
    "predict_val = sm.add_constant(prediction)\n",
    "# Simpler.\n",
    "print(f'Predicted: {fitted_cloglog.predict(predict_val)}')\n",
    "\n",
    "# Isolated. This one grabs the item \"values\" from the array.\n",
    "print(f'Predicted: {fitted_cloglog.predict(predict_val).values[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model comparisons. From https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIC</th>\n",
       "      <th>AICC</th>\n",
       "      <th>BIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logit</th>\n",
       "      <td>46.071421</td>\n",
       "      <td>49.182532</td>\n",
       "      <td>58.560749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probit</th>\n",
       "      <td>46.506191</td>\n",
       "      <td>49.617302</td>\n",
       "      <td>58.995518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloglog</th>\n",
       "      <td>44.797092</td>\n",
       "      <td>47.908203</td>\n",
       "      <td>57.286420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AIC       AICC        BIC\n",
       "logit    46.071421  49.182532  58.560749\n",
       "probit   46.506191  49.617302  58.995518\n",
       "cloglog  44.797092  47.908203  57.286420"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[aic_logit,aicc_logit,bic_logit],\n",
    "        [aic_probit,aicc_probit,bic_probit],\n",
    "        [aic_cloglog,aicc_cloglog,bic_cloglog]]\n",
    "\n",
    "comparison = pd.DataFrame(data,\n",
    "                          columns = ['AIC','AICC','BIC'],\n",
    "                          index = ['logit','probit','cloglog'])\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated comparison. \n",
    "https://www.geeksforgeeks.org/get-minimum-values-in-rows-or-columns-with-their-index-position-in-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the best fit is the cloglog model.\n"
     ]
    }
   ],
   "source": [
    "# Initialize.\n",
    "logit = 0\n",
    "probit = 0\n",
    "cloglog = 0 \n",
    "\n",
    "# Runs through all 3 columns.\n",
    "# If column has lowest value, that model +1 point.\n",
    "# Model with highest points is declared at end.\n",
    "def points(cur_min,logit,probit,cloglog):\n",
    "        if cur_min == \"logit\":\n",
    "                logit += 1\n",
    "        elif cur_min == \"probit\":\n",
    "                probit += 1\n",
    "        else:\n",
    "                cloglog += 1 \n",
    "        return(logit,probit,cloglog)\n",
    "\n",
    "# Runs through the models.\n",
    "cur_min = comparison['AIC'].idxmin()\n",
    "logit,probit,cloglog = points(cur_min,logit,probit,cloglog)\n",
    "cur_min = comparison['AICC'].idxmin()\n",
    "logit,probit,cloglog = points(cur_min,logit,probit,cloglog)\n",
    "cur_min = comparison['BIC'].idxmin()\n",
    "logit,probit,cloglog = points(cur_min,logit,probit,cloglog)\n",
    "\n",
    "final = {logit:\"logit\",probit:\"probit\",cloglog:\"cloglog\"}\n",
    "\n",
    "print(f\"The model with the best fit is the {final.get(max(final))} model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regressions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
